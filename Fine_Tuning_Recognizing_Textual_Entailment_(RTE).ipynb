{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNZHFjpdeFooinrmBMJIdql",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/qmeng222/transformers-for-NLP/blob/main/Fine_Tuning_Recognizing_Textual_Entailment_(RTE).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# About the project:\n",
        "---\n",
        "Text classifier with 2 input sentences."
      ],
      "metadata": {
        "id": "sjzm8Q4A0f3J"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the dataset:"
      ],
      "metadata": {
        "id": "dcX3NR38OmdH"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f109vN4GtYUX",
        "outputId": "e6c4095d-aaf9-477c-bc90-73c6edfceca6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (2.15.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.1)\n",
            "Requirement already satisfied: pyarrow>=8.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (9.0.0)\n",
            "Requirement already satisfied: pyarrow-hotfix in /usr/local/lib/python3.10/dist-packages (from datasets) (0.5)\n",
            "Requirement already satisfied: dill<0.3.8,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.7)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (1.5.3)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.4.1)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.15)\n",
            "Requirement already satisfied: fsspec[http]<=2023.10.0,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (2023.6.0)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.8.6)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (23.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4.0,>=2.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (3.3.2)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.0.4)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.9.2)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers) (4.5.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2023.7.22)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2023.3.post1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.1->pandas->datasets) (1.16.0)\n"
          ]
        }
      ],
      "source": [
        "# install libraries:\n",
        "!pip install transformers datasets\n",
        "# `transformers` library: for working with pre-trained NLP models\n",
        "# `datasets` library: for working with datasets"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from datasets import load_dataset # from `datasets` library, import the `load_dataset` func for downloading datasets\n",
        "import numpy as np # import `numpy` library for numerical computations in Python"
      ],
      "metadata": {
        "id": "mrI9lHVY1oVh"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the `load_dataset` func to load the RTE (Recognizing Textual Entailment) dataset from the GLUE (General Language Understanding Evaluation) benchmark:\n",
        "raw_datasets = load_dataset(\"glue\", \"rte\")\n",
        "# benchmark is a standardized set of tasks or datasets that are used to evaluate the performance of ML models\n",
        "# RTE is a task to determine whether one piece of text logically entails another"
      ],
      "metadata": {
        "id": "f9qtXrc52RP9"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine the raw dataset:"
      ],
      "metadata": {
        "id": "keHIy-wIOv2g"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "type(raw_datasets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vYD5eKvTD9Z7",
        "outputId": "beab3a47-7510-49ce-ceaf-dd09cf503431"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "datasets.dataset_dict.DatasetDict"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q5Ca95OkEG8A",
        "outputId": "686fa0ed-a674-4d45-d7f3-b0f1445b11bc"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'train': (2490, 4), 'validation': (277, 4), 'test': (3000, 4)}"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LuuzInA-EBc2",
        "outputId": "1715a9eb-c8fc-4d1a-a009-4c9f89dcc5e9"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "DatasetDict({\n",
              "    train: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 2490\n",
              "    })\n",
              "    validation: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 277\n",
              "    })\n",
              "    test: Dataset({\n",
              "        features: ['sentence1', 'sentence2', 'label', 'idx'],\n",
              "        num_rows: 3000\n",
              "    })\n",
              "})"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# check the attributes:\n",
        "raw_datasets['train'].features"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ESM7_4VJEMPq",
        "outputId": "7aa1b199-f371-41d1-bb04-4af9ad086c66"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'sentence1': Value(dtype='string', id=None),\n",
              " 'sentence2': Value(dtype='string', id=None),\n",
              " 'label': ClassLabel(names=['entailment', 'not_entailment'], id=None),\n",
              " 'idx': Value(dtype='int32', id=None)}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Examine each feature within the training subset:"
      ],
      "metadata": {
        "id": "zkieCeIuODbU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train']['sentence1'][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "osA-vV4CKDzR",
        "outputId": "8b6ad09c-8546-480d-acfb-c9f59881a250"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['No Weapons of Mass Destruction Found in Iraq Yet.',\n",
              " 'A place of sorrow, after Pope John Paul II died, became a place of celebration, as Roman Catholic faithful gathered in downtown Chicago to mark the installation of new Pope Benedict XVI.',\n",
              " 'Herceptin was already approved to treat the sickest breast cancer patients, and the company said, Monday, it will discuss with federal regulators the possibility of prescribing the drug for more breast cancer patients.']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘† A list."
      ],
      "metadata": {
        "id": "EgM_axkhgqlA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train']['sentence2'][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bdxGxXFQNcRs",
        "outputId": "295f4b53-8ded-4e86-9f15-77a0e0dda55d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['Weapons of Mass Destruction Found in Iraq.',\n",
              " 'Pope Benedict XVI is the new leader of the Roman Catholic Church.',\n",
              " 'Herceptin can be used to treat breast cancer.']"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train']['label'][:3]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fuU_7DZdNmlB",
        "outputId": "88a10bcc-c037-4fb2-d3fb-47d57141b01b"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1, 0, 0]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "raw_datasets['train']['idx'][3:6]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TCJbtNG3NzBU",
        "outputId": "c53c4752-4f43-4496-985d-71200c9e000f"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[3, 4, 5]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Tokenize:"
      ],
      "metadata": {
        "id": "9MXyNjbqPKw6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import classes from the HF transformers library:\n",
        "from transformers import AutoTokenizer, AutoModelForSequenceClassification, Trainer, TrainingArguments\n",
        "# `AutoTokenizer` class: automatically load the appropriate tokenizer for a specific pre-trained model\n",
        "# `AutoModelForSequenceClassification` class: automatically load a pre-trained model suitable for sequence classification based on the provided model identifier\n",
        "# `AutoConfig` class: load a pre-configured model configuration based on the model identifier or name\n",
        "# `Trainer` calss: for training and evaluating models\n",
        "# `TrainingArguments` class: customize the training arguments (hyperparameters etc.) for the training process"
      ],
      "metadata": {
        "id": "hj9rM9xiPaVM"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model identifier (specify the name of a pre-trained model):\n",
        "checkpoint = 'distilbert-base-cased' # or checkpoint = 'bert-base-cased'"
      ],
      "metadata": {
        "id": "9LvYz7SGN8ag"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# automatically load the appropriate tokenizer:\n",
        "tokenizer = AutoTokenizer.from_pretrained(checkpoint)"
      ],
      "metadata": {
        "id": "eIk6O4MvdBlL"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# tokenize the 1st pair of sentences:\n",
        "tokenizer(\n",
        "    raw_datasets['train']['sentence1'][0],\n",
        "    raw_datasets['train']['sentence2'][0]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rectbt7CdUpf",
        "outputId": "3f9437d4-121f-46f0-e7fa-a8bbbd231792"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1302, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 6355, 119, 102, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# assign the res of the last expression to a variable\n",
        "result = _"
      ],
      "metadata": {
        "id": "fSEU_J2EhC7d"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4y2tdYT4pLIO",
        "outputId": "4fa540da-2e88-4579-c195-6e455a32e5e8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'input_ids': [101, 1302, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 6355, 119, 102, 20263, 1104, 8718, 14177, 17993, 17107, 1107, 5008, 119, 102], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# convert a sequence of token ids back into a human-readable string:\n",
        "tokenizer.decode(result['input_ids'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "id": "azOMrHWqqU5Q",
        "outputId": "a8cc71b9-c4c4-4c1a-c53f-d7b39008ff23"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'[CLS] No Weapons of Mass Destruction Found in Iraq Yet. [SEP] Weapons of Mass Destruction Found in Iraq. [SEP]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "ðŸ‘† CLS (classification) token added to the beginning of the sequence.\n",
        "\n",
        "SEP (separator) token to separate different segments of the sequence, especially in tasks involving multiple sentences or sequences."
      ],
      "metadata": {
        "id": "XKOqybTjTjaF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Load the pre-trained model:"
      ],
      "metadata": {
        "id": "hvBQ6IeFuSqA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# automatically load a pre-trained model suitable for sequence classification based on the provided model identifier:\n",
        "model = AutoModelForSequenceClassification.from_pretrained(checkpoint, num_labels=2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MRMg6mEY85bx",
        "outputId": "e5f2da65-5dff-465a-eb80-f37325fd0139"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.weight', 'classifier.bias', 'pre_classifier.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Evaluate model performance:"
      ],
      "metadata": {
        "id": "4sS1hLGEqzIj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from `datasets` library, import the `load_metric` func to use pre-defined evaluation metrics for assessing the model performance:\n",
        "from datasets import load_metric"
      ],
      "metadata": {
        "id": "yTpO5uNhos7E"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# load the evaluation metric associated with the RTE task from the GLUE benchmark:\n",
        "metric = load_metric(\"glue\", \"rte\")\n",
        "metric"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xslPuuWepQOA",
        "outputId": "3a179c8a-2dfb-4b44-a4f0-f311a9498262"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "<ipython-input-21-3a71a8835654>:2: FutureWarning: load_metric is deprecated and will be removed in the next major version of datasets. Use 'evaluate.load' instead, from the new library ðŸ¤— Evaluate: https://huggingface.co/docs/evaluate\n",
            "  metric = load_metric(\"glue\", \"rte\")\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Metric(name: \"glue\", features: {'predictions': Value(dtype='int64', id=None), 'references': Value(dtype='int64', id=None)}, usage: \"\"\"\n",
              "Compute GLUE evaluation metric associated to each GLUE dataset.\n",
              "Args:\n",
              "    predictions: list of predictions to score.\n",
              "        Each translation should be tokenized into a list of tokens.\n",
              "    references: list of lists of references for each translation.\n",
              "        Each reference should be tokenized into a list of tokens.\n",
              "Returns: depending on the GLUE subset, one or several of:\n",
              "    \"accuracy\": Accuracy\n",
              "    \"f1\": F1 score\n",
              "    \"pearson\": Pearson Correlation\n",
              "    \"spearmanr\": Spearman Correlation\n",
              "    \"matthews_correlation\": Matthew Correlation\n",
              "Examples:\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'sst2')  # 'sst2' or any of [\"mnli\", \"mnli_mismatched\", \"mnli_matched\", \"qnli\", \"rte\", \"wnli\", \"hans\"]\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'mrpc')  # 'mrpc' or 'qqp'\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'accuracy': 1.0, 'f1': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'stsb')\n",
              "    >>> references = [0., 1., 2., 3., 4., 5.]\n",
              "    >>> predictions = [0., 1., 2., 3., 4., 5.]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print({\"pearson\": round(results[\"pearson\"], 2), \"spearmanr\": round(results[\"spearmanr\"], 2)})\n",
              "    {'pearson': 1.0, 'spearmanr': 1.0}\n",
              "\n",
              "    >>> glue_metric = datasets.load_metric('glue', 'cola')\n",
              "    >>> references = [0, 1]\n",
              "    >>> predictions = [0, 1]\n",
              "    >>> results = glue_metric.compute(predictions=predictions, references=references)\n",
              "    >>> print(results)\n",
              "    {'matthews_correlation': 1.0}\n",
              "\"\"\", stored examples: 0)"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# use the `compute` method of a loaded metric for a dummy evaluation:\n",
        "metric.compute(predictions=[1, 1, 1], references=[1, 0, 0])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NonHGehVpqP0",
        "outputId": "c589f0b6-5089-4eae-8de7-f85c9d24404f"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 0.3333333333333333}"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from the `metrics` module within the `sklearn` library, import the `f1_score` func\n",
        "# to compute the F1 score for evaluating classification models:\n",
        "from sklearn.metrics import f1_score"
      ],
      "metadata": {
        "id": "BAmNDcoXqrhu"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# compute evaluation metrics based on the logits (raw predictions) and true labels:\n",
        "def compute_metrics(logits_and_labels):\n",
        "  logits, labels = logits_and_labels # unpack the tuple, which is provided by the evaluation loop of a model\n",
        "  predictions = np.argmax(logits, axis=-1) # (for classification purpose) compute the predictions by taking the index of the maximum logit along the last axis\n",
        "  acc = np.mean(predictions == labels) # compute the ave accuracy\n",
        "  f1 = f1_score(labels, predictions) # compute the F1 score\n",
        "  return {'accuracy': acc, 'f1': f1} # return a dict containing the computed metrics"
      ],
      "metadata": {
        "id": "CxvvhIudrqSw"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# this function takes a batch of examples\n",
        "# where each example is a dictionary with keys 'sentence1' and 'sentence2'\n",
        "# the values associated with these keys are the text sentences to be tokenized\n",
        "# truncate the tokens if they exceed the maximum token length supported by the tokenizer\n",
        "def tokenize_fn(batch):\n",
        "  return tokenizer(batch['sentence1'], batch['sentence2'], truncation=True)"
      ],
      "metadata": {
        "id": "jYQAry7kt9bU"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# apply the `tokenize_fn` function to each batch of examples in the `raw_datasets`:\n",
        "tokenized_datasets = raw_datasets.map(tokenize_fn, batched=True)"
      ],
      "metadata": {
        "id": "_g61YsMS5oXk"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# The trainer (for training and evaluation):"
      ],
      "metadata": {
        "id": "am2z4_Kn7agD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers[torch]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HAaCuXNdvJt3",
        "outputId": "bcf28bc6-244a-468e-c65b-cfa0748b3de1"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers[torch] in /usr/local/lib/python3.10/dist-packages (4.35.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (3.13.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.19.3)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (1.23.5)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (23.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (6.0.1)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2023.6.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.31.0)\n",
            "Requirement already satisfied: tokenizers<0.19,>=0.14 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.15.0)\n",
            "Requirement already satisfied: safetensors>=0.3.1 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.4.0)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (4.66.1)\n",
            "Requirement already satisfied: torch!=1.12.0,>=1.10 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (2.1.0+cu118)\n",
            "Requirement already satisfied: accelerate>=0.20.3 in /usr/local/lib/python3.10/dist-packages (from transformers[torch]) (0.24.1)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from accelerate>=0.20.3->transformers[torch]) (5.9.5)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (2023.6.0)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.16.4->transformers[torch]) (4.5.0)\n",
            "Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (1.12)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.2.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (3.1.2)\n",
            "Requirement already satisfied: triton==2.1.0 in /usr/local/lib/python3.10/dist-packages (from torch!=1.12.0,>=1.10->transformers[torch]) (2.1.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (3.4)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers[torch]) (2023.7.22)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch!=1.12.0,>=1.10->transformers[torch]) (2.1.3)\n",
            "Requirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->torch!=1.12.0,>=1.10->transformers[torch]) (1.3.0)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create an instance of the `TrainingArguments` class with specific configuration settings:\n",
        "training_args = TrainingArguments(\n",
        "    output_dir='training_dir', # specify the directory where the trained model and associated files will be saved\n",
        "    evaluation_strategy='epoch', # evaluation (validation) will be performed at the end of each epoch\n",
        "    save_strategy='epoch', # a checkpoint - a snapshot of the model's parameters (weights and biases) and other relevant info) - will be saved to disk at the end of each epoch\n",
        "    num_train_epochs=5, # the model will be trained for 5 epochs\n",
        "    per_device_train_batch_size=16, # how many training examples will be processed in each forward and backward pass\n",
        "    per_device_eval_batch_size=64, # each eval batch will contain 64 examples\n",
        "    logging_steps=150, # after every 150 batches, the training logs will be displayed; otherwise 'no log' will appear\n",
        ")"
      ],
      "metadata": {
        "id": "BfH4cCmdw1Vd"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# configure an instance of the `Trainer` class:\n",
        "trainer = Trainer(\n",
        "    model, # the model to be trained or fine-tuned (the model created using `AutoModelForSequenceClassification.from_pretrained()`)\n",
        "    training_args, # the instance of the TrainingArguments class\n",
        "    train_dataset=tokenized_datasets[\"train\"], # refer to the `tokenized_datasets`\n",
        "    eval_dataset=tokenized_datasets[\"validation\"],\n",
        "    tokenizer=tokenizer, # the tokenizer loaded to preprocess the input data\n",
        "    compute_metrics=compute_metrics, # the func for computing evaluation metrics\n",
        ")"
      ],
      "metadata": {
        "id": "nSmjVBBv6oyN"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train the model (forward, backward, update params, logging, eval):\n",
        "trainer.train()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "CMSjogRK95bk",
        "outputId": "ae3e3444-a1a0-4ac2-fc5a-57030c8fc53d"
      },
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "You're using a DistilBertTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='780' max='780' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [780/780 03:27, Epoch 5/5]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Epoch</th>\n",
              "      <th>Training Loss</th>\n",
              "      <th>Validation Loss</th>\n",
              "      <th>Accuracy</th>\n",
              "      <th>F1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <td>1</td>\n",
              "      <td>0.698300</td>\n",
              "      <td>0.693570</td>\n",
              "      <td>0.530686</td>\n",
              "      <td>0.644809</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>2</td>\n",
              "      <td>0.643700</td>\n",
              "      <td>0.745733</td>\n",
              "      <td>0.501805</td>\n",
              "      <td>0.530612</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>3</td>\n",
              "      <td>0.401800</td>\n",
              "      <td>1.009437</td>\n",
              "      <td>0.534296</td>\n",
              "      <td>0.509506</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>4</td>\n",
              "      <td>0.192300</td>\n",
              "      <td>1.560241</td>\n",
              "      <td>0.552347</td>\n",
              "      <td>0.474576</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <td>5</td>\n",
              "      <td>0.100400</td>\n",
              "      <td>1.960213</td>\n",
              "      <td>0.534296</td>\n",
              "      <td>0.527473</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=780, training_loss=0.39399332159604783, metrics={'train_runtime': 210.4194, 'train_samples_per_second': 59.168, 'train_steps_per_second': 3.707, 'total_flos': 544524318051096.0, 'train_loss': 0.39399332159604783, 'epoch': 5.0})"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# save the trained model and its associated training state to a specified directory:\n",
        "trainer.save_model('my_saved_model')"
      ],
      "metadata": {
        "id": "0yBJoJph-GV1"
      },
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Transformer pipeline:"
      ],
      "metadata": {
        "id": "bQ26cMP_vVff"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# from the HF transformers library, import the pipeline class for using pre-trained models:\n",
        "from transformers import pipeline\n",
        "\n",
        "# create a 'text classification' pipeline that uses a previously trained model checkpoint:\n",
        "p = pipeline(\n",
        "    'text-classification', # specify the task for the pipeline\n",
        "    model='my_saved_model', # specify the path of the pre-trained model checkpoint\n",
        "    device=0 # use GPU if possible\n",
        ")"
      ],
      "metadata": {
        "id": "nHLnhLqm-lFx"
      },
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# use the text classification pipeline to classify a pair of texts\n",
        "p({'text': 'I went to the store', 'text_pair': 'I am a bird'})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "P-_6s39uAo0Q",
        "outputId": "bc768fa0-ceb4-46c1-d97e-77e8e99a44f6"
      },
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'label': 'LABEL_1', 'score': 0.8360171914100647}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    }
  ]
}